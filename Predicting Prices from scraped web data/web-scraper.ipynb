{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Web Scraper code\nFor web scraping I have used selenium along with beutiful soup. Selenium was necessary according to the URL that has been provided. The data that we want is spread over 711 pages with 50 rows on each page except the last page. The URL for each page is also the same. So even if we copy pasted the URL when we're viewing the 100th page, in a new tab that would still show us the first page itself. \n> Thus, its necessary to iterate through each page of the table. For this automation process, as we want to view the table after clicking the next button I have used selenium.","metadata":{}},{"cell_type":"code","source":"# installing the necessary packages\n!pip install selenium\n!pip install beautifulsoup4 \n!pip install webdriver-manager      # this makes it easier to load browser configurations for selenium","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As there are 711 pages, we need to get the data from each page then click the next button and wait till the next page loads. Then we get the data from that page and continue with the same process. \nSome important points of the source that we are scraping from:\n* URL for each page of the table is the same, hence looping through URL values isn't possible\n* Note that the first page has only 2 buttons i.e. 'Next' and 'Last' & the last page has 'Prev' and 'First'\n* Every other page has 4 buttons i.e. 'Next' 'Last' 'Prev' 'First'\n* After any of the buttons is clicked the website takes some time to show the result of the same, about 10-15 seconds","metadata":{}},{"cell_type":"markdown","source":"Keeping these points in mind, we deal with the first page separately and then the rest of them through a loop which iterates 710 times. I have explicitly put a sleep of 20 seconds wherever necessary so that the page has been loaded before we try to extract the data. I am finding the button and the table using selectors that I got from inspect element of the URL.\n\n> The detailed reason for keeping the first page different is that the selector for the 'Next' button on the first page and pages after that are different.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport time\nfrom selenium import webdriver\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\nlink = \"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=78&Tx_State=KK&Tx_District=0&Tx_Market=0&DateFrom=01-Jan-2015&DateTo=01-Feb-2021&Fr_Date=01-Jan-2015&To_Date=01-Feb-2021&Tx_Trend=0&Tx_CommodityHead=Tomato&Tx_StateHead=Karnataka&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--\"\n\nwith webdriver.Chrome(ChromeDriverManager().install()) as driver:\n    driver.get(link)\n\n    datalist = []\n    \n    wait = WebDriverWait(driver, 10)\n    \n    x = 1   # page counter\n    \n    if x == 1:\n        show_more = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#cphBody_GridPriceData > tbody > tr:nth-child(52) > td > table > tbody > tr > td:nth-child(1) > input[type=image]\")))\n        show_more.click()\n        time.sleep(20)\n\n        for elem in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,\"#cphBody_GridPriceData tr\"))):\n            data = [item.text for item in elem.find_elements_by_css_selector(\"td\")]\n            datalist.append(data)\n        x = x + 1\n    \n    while x < 712:\n        show_more = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#cphBody_GridPriceData > tbody > tr:nth-child(52) > td > table > tbody > tr > td:nth-child(3) > input[type=image]\")))\n        show_more.click()\n        time.sleep(20)\n\n        for elem in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,\"#cphBody_GridPriceData tr\"))):\n            data = [item.text for item in elem.find_elements_by_css_selector(\"td\")]\n            datalist.append(data)\n        x = x + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to pandas dataframe\ndf = pd.DataFrame(datalist)\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to csv format\ndf.to_csv('Agri_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
